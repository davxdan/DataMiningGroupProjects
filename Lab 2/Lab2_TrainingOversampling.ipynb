{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 1 to 30000\n",
      "Data columns (total 20 columns):\n",
      "SEX                  30000 non-null int64\n",
      "PAY_0                30000 non-null int32\n",
      "default              30000 non-null int64\n",
      "log_LIMIT_BAL        30000 non-null float64\n",
      "log_PAY_AMT1         30000 non-null float64\n",
      "EDUCATION_1          30000 non-null uint8\n",
      "EDUCATION_2          30000 non-null uint8\n",
      "EDUCATION_3          30000 non-null uint8\n",
      "EDUCATION_4          30000 non-null uint8\n",
      "MARRIAGE_1           30000 non-null uint8\n",
      "MARRIAGE_2           30000 non-null uint8\n",
      "MARRIAGE_3           30000 non-null uint8\n",
      "AGEGROUP_0           30000 non-null uint8\n",
      "AGEGROUP_1           30000 non-null uint8\n",
      "AGEGROUP_2           30000 non-null uint8\n",
      "AGEGROUP_3           30000 non-null uint8\n",
      "AGEGROUP_4           30000 non-null uint8\n",
      "AGEGROUP_5           30000 non-null uint8\n",
      "TotalLatePayments    30000 non-null int64\n",
      "PayrateGroup         30000 non-null float64\n",
      "dtypes: float64(3), int32(1), int64(3), uint8(13)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "#import all packages for this notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('DefaultCreditcardClients.csv')\n",
    "df.rename(columns={'default payment next month':'default'}, inplace=True)\n",
    "\n",
    "#set index to the \"ID\" value and remove the ID column\n",
    "df.index = df.ID\n",
    "del df['ID']\n",
    "\n",
    "#Create Lists for Analysis\n",
    "continuous_features = ['LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2','BILL_AMT3',\n",
    "                       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "                       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
    "                       'PAY_AMT6']\n",
    "ordinal_features = ['EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0','PAY_2', 'PAY_3',\n",
    "                    'PAY_4', 'PAY_5', 'PAY_6','default']\n",
    "\n",
    "#Convert datatypes\n",
    "df[continuous_features] = df[continuous_features].astype(np.float64)\n",
    "df[ordinal_features] = df[ordinal_features].astype(np.int64)\n",
    "\n",
    "#convert any non-identified education categories to 'OTHER'\n",
    "df['EDUCATION'] = df['EDUCATION'].replace(to_replace=(0,5,6),value=4)\n",
    "\n",
    "#convert any non-identified marriage categories to 'OTHER'\n",
    "df['MARRIAGE'] = df['MARRIAGE'].replace(to_replace=(0),value=3)\n",
    "\n",
    "#Log transform continuous variables; as they each have a mostly \n",
    "##exponential distribution\n",
    "df[\"log_LIMIT_BAL\"]=np.log(df.LIMIT_BAL)\n",
    "df[\"log_PAY_AMT1\"]=np.log(df.PAY_AMT1+1)\n",
    "\n",
    "# #bin the ages based on various age groups \n",
    "bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "labels = [0,1,2,3,4,5]\n",
    "df['AGEGROUP'] = pd.cut(df['AGE'], bins=bins, labels=labels)\n",
    "\n",
    "\n",
    "# One-hot encoding of \"EDUCATION\" and \"MARRIAGE\".\n",
    "tmp_df_1 = pd.get_dummies(df.EDUCATION,prefix='EDUCATION')\n",
    "tmp_df_2 = pd.get_dummies(df.MARRIAGE,prefix='MARRIAGE')\n",
    "tmp_df_3 = pd.get_dummies(df.AGEGROUP,prefix='AGEGROUP')\n",
    "df = pd.concat((df,tmp_df_1,tmp_df_2,tmp_df_3),axis=1)\n",
    "\n",
    "\n",
    "# flag all the payment histor to late vs not late\n",
    "payments = ['PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']\n",
    "bins = [-10, 2, 10]\n",
    "labels = [0,1]\n",
    "for fi,feature in enumerate(payments):\n",
    "    df[feature] = pd.cut(df[feature], bins=bins, labels=labels).astype(np.int)\n",
    "#count how many total late payments have been made\n",
    "df['TotalLatePayments'] = df[payments].sum(axis=1)\n",
    "\n",
    "# Creating an Attribute for % of billed Amounts Paid.  Cards not used have a rate of 1000\n",
    "# Charts showing relationship of this variable to Default is in the Appendix.\n",
    "df['TotalBilled'] = df.BILL_AMT1+df.BILL_AMT2+df.BILL_AMT3+df.BILL_AMT4+df.BILL_AMT5+df.BILL_AMT5\n",
    "df['TotalPaid'] = df.PAY_AMT1+df.PAY_AMT2+df.PAY_AMT3+df.PAY_AMT4+df.PAY_AMT5+df.BILL_AMT5\n",
    "\n",
    "df['PayRateCalc']  =  df['TotalPaid']/df['TotalBilled']\n",
    "df['PayRateLimit'] = 0\n",
    "df['PayRate'] = df['PayRateCalc'].where(df['PayRateCalc'] < 1.25, 1.25)\n",
    "df['PayRate'] = df['PayRate'].where(df['TotalBilled'] > 0, 1000) # Approximately isolates Cards not used.\n",
    "df['PayRate'] = df['PayRate'].where(df['PayRate'] > 0, 0)\n",
    "\n",
    "df['PayrateGroup'] = df['PayRate']*100//5*5\n",
    "\n",
    "#Create a separate dataset in case we need to come back to original\n",
    "dfsub = df.copy()\n",
    "#dfsub = pd.concat((df,tmp_df_1,tmp_df_2),axis=1)\n",
    "\n",
    "#We will not need these attributes. We are using log of them instead.\n",
    "deleteVar = ['LIMIT_BAL','PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6',\n",
    "            'BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6',\n",
    "            'EDUCATION','MARRIAGE','AGEGROUP','AGE','TotalBilled','TotalPaid',\n",
    "            'PayRateCalc','PayRateLimit','PayRate','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']\n",
    "\n",
    "for fi,feature in enumerate(deleteVar):\n",
    "    del dfsub[feature]\n",
    "\n",
    "dfsub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training data  (23943, 20)\n",
      "Dimensions of test are  (6057, 20)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23943 entries, 1 to 30000\n",
      "Data columns (total 20 columns):\n",
      "SEX                  23943 non-null int64\n",
      "PAY_0                23943 non-null int32\n",
      "default              23943 non-null int64\n",
      "log_LIMIT_BAL        23943 non-null float64\n",
      "log_PAY_AMT1         23943 non-null float64\n",
      "EDUCATION_1          23943 non-null uint8\n",
      "EDUCATION_2          23943 non-null uint8\n",
      "EDUCATION_3          23943 non-null uint8\n",
      "EDUCATION_4          23943 non-null uint8\n",
      "MARRIAGE_1           23943 non-null uint8\n",
      "MARRIAGE_2           23943 non-null uint8\n",
      "MARRIAGE_3           23943 non-null uint8\n",
      "AGEGROUP_0           23943 non-null uint8\n",
      "AGEGROUP_1           23943 non-null uint8\n",
      "AGEGROUP_2           23943 non-null uint8\n",
      "AGEGROUP_3           23943 non-null uint8\n",
      "AGEGROUP_4           23943 non-null uint8\n",
      "AGEGROUP_5           23943 non-null uint8\n",
      "TotalLatePayments    23943 non-null int64\n",
      "PayrateGroup         23943 non-null float64\n",
      "dtypes: float64(3), int32(1), int64(3), uint8(13)\n",
      "memory usage: 1.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6057 entries, 9 to 29992\n",
      "Data columns (total 20 columns):\n",
      "SEX                  6057 non-null int64\n",
      "PAY_0                6057 non-null int32\n",
      "default              6057 non-null int64\n",
      "log_LIMIT_BAL        6057 non-null float64\n",
      "log_PAY_AMT1         6057 non-null float64\n",
      "EDUCATION_1          6057 non-null uint8\n",
      "EDUCATION_2          6057 non-null uint8\n",
      "EDUCATION_3          6057 non-null uint8\n",
      "EDUCATION_4          6057 non-null uint8\n",
      "MARRIAGE_1           6057 non-null uint8\n",
      "MARRIAGE_2           6057 non-null uint8\n",
      "MARRIAGE_3           6057 non-null uint8\n",
      "AGEGROUP_0           6057 non-null uint8\n",
      "AGEGROUP_1           6057 non-null uint8\n",
      "AGEGROUP_2           6057 non-null uint8\n",
      "AGEGROUP_3           6057 non-null uint8\n",
      "AGEGROUP_4           6057 non-null uint8\n",
      "AGEGROUP_5           6057 non-null uint8\n",
      "TotalLatePayments    6057 non-null int64\n",
      "PayrateGroup         6057 non-null float64\n",
      "dtypes: float64(3), int32(1), int64(3), uint8(13)\n",
      "memory usage: 431.8 KB\n"
     ]
    }
   ],
   "source": [
    "split = np.random.rand(len(dfsub)) < 0.8\n",
    "\n",
    "df_train = dfsub[split]\n",
    "df_test = dfsub[~split]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# fit training for scaling after upsampling\n",
    "X_train = df_train.drop(columns=['default']).values     \n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "\n",
    "print(\"Dimensions of training data \" , df_train.shape)\n",
    "print(\"Dimensions of test are \" , df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "0    18669\n",
      "1    18569\n",
      "Name: default, dtype: int64\n",
      "Dimensions of training features are  (37238, 19)\n",
      "Dimensions of training target are  (37238,)\n",
      "Dimensions of testing features are  (6057, 19)\n",
      "Dimensions of testing target are  (6057,)\n"
     ]
    }
   ],
   "source": [
    "target_count = dfsub.default.value_counts()\n",
    "# Class count\n",
    "df_class_0, df_class_1 = df_train.default.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df_train[df_train['default'] == 0]\n",
    "df_class_1 = df_train[df_train['default'] == 1]\n",
    "\n",
    "df_class_1_over = df_class_1.sample(frac=target_count[0]/target_count[1], replace=True)\n",
    "df_OverSampled = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "print('Random over-sampling:')\n",
    "print(df_OverSampled.default.value_counts())\n",
    "\n",
    "\n",
    "#Isolate the \"default\" variable into y and keep everythign else in X to use for predictions:\n",
    "if 'default' in df_OverSampled:\n",
    "    y_train = df_OverSampled['default'].values\n",
    "    del df_OverSampled['default'] \n",
    "    X_train = df_OverSampled.values\n",
    "    \n",
    "if 'default' in df_test:\n",
    "    y_test = df_test['default'].values\n",
    "    del df_test['default'] \n",
    "    X_test = df_test.values\n",
    "\n",
    "print(\"Dimensions of training features are \" , X_train.shape)\n",
    "print(\"Dimensions of training target are \" , y_train.shape)\n",
    "print(\"Dimensions of testing features are \" , X_test.shape)\n",
    "print(\"Dimensions of testing target are \" , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the previously fit scalines to transform the data after the over sampling\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
