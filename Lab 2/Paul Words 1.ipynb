{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Team\n",
    "\n",
    "- Daniel Davieau\n",
    "- Nathan Wall\n",
    "- Olga Tanyuk\n",
    "- Paul Panek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 1 to 30000\n",
      "Data columns (total 18 columns):\n",
      "SEX              30000 non-null int64\n",
      "EDUCATION        30000 non-null int64\n",
      "MARRIAGE         30000 non-null int64\n",
      "AGE              30000 non-null int64\n",
      "default          30000 non-null int64\n",
      "PAY_0            30000 non-null int64\n",
      "PAY_2            30000 non-null int64\n",
      "PAY_3            30000 non-null int64\n",
      "PAY_4            30000 non-null int64\n",
      "PAY_5            30000 non-null int64\n",
      "PAY_6            30000 non-null int64\n",
      "log_LIMIT_BAL    30000 non-null float64\n",
      "log_PAY_AMT1     30000 non-null float64\n",
      "log_PAY_AMT2     30000 non-null float64\n",
      "log_PAY_AMT3     30000 non-null float64\n",
      "log_PAY_AMT4     30000 non-null float64\n",
      "log_PAY_AMT5     30000 non-null float64\n",
      "log_PAY_AMT6     30000 non-null float64\n",
      "dtypes: float64(7), int64(11)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/CreditcardDefaults.csv')\n",
    "df.rename(columns={'default payment next month':'default'}, inplace=True)\n",
    "\n",
    "#set index to the \"ID\" value and remove the ID column\n",
    "df.index = df.ID\n",
    "del df['ID']\n",
    "\n",
    "#Create Lists for Analysis\n",
    "continuous_features = ['LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2','BILL_AMT3',\n",
    "                       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "                       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
    "                       'PAY_AMT6']\n",
    "ordinal_features = ['EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0','PAY_2', 'PAY_3',\n",
    "                    'PAY_4', 'PAY_5', 'PAY_6','default']\n",
    "\n",
    "#Convert datatypes\n",
    "df[continuous_features] = df[continuous_features].astype(np.float64)\n",
    "df[ordinal_features] = df[ordinal_features].astype(np.int64)\n",
    "\n",
    "#convert any non-identified education categories to 'OTHER'\n",
    "df['EDUCATION'] = df['EDUCATION'].replace(to_replace=(0,5,6),value=4)\n",
    "\n",
    "#convert any non-identified marriage categories to 'OTHER'\n",
    "df['MARRIAGE'] = df['MARRIAGE'].replace(to_replace=(0),value=3)\n",
    "\n",
    "#Log transform continuous variables; as they each have a mostly \n",
    "##exponential distribution\n",
    "df[\"log_LIMIT_BAL\"]=np.log(df.LIMIT_BAL)\n",
    "df[\"log_PAY_AMT1\"]=np.log(df.PAY_AMT1+1)\n",
    "df[\"log_PAY_AMT2\"]=np.log(df.PAY_AMT2+1)\n",
    "df[\"log_PAY_AMT3\"]=np.log(df.PAY_AMT3+1)\n",
    "df[\"log_PAY_AMT4\"]=np.log(df.PAY_AMT4+1)\n",
    "df[\"log_PAY_AMT5\"]=np.log(df.PAY_AMT5+1)\n",
    "df[\"log_PAY_AMT6\"]=np.log(df.PAY_AMT6+1)\n",
    "\n",
    "#Create a separate dataset with only useful variables as identified in Lab1 and Mini-lab1.\n",
    "df = df[['SEX','EDUCATION','MARRIAGE','AGE', 'default'\n",
    "            ,'PAY_0','PAY_2', 'PAY_3', 'PAY_4', 'PAY_5','PAY_6', \"log_LIMIT_BAL\"\n",
    "            ,\"log_PAY_AMT1\",\"log_PAY_AMT2\",\"log_PAY_AMT3\",\"log_PAY_AMT4\",\"log_PAY_AMT5\"\n",
    "            ,\"log_PAY_AMT6\"]]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training data  (24107, 23)\n",
      "Dimensions of test are  (5893, 23)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding of \"EDUCATION\" and \"MARRIAGE\".\n",
    "tmp_df_1 = pd.get_dummies(df.EDUCATION,prefix='EDUCATION')\n",
    "tmp_df_2 = pd.get_dummies(df.MARRIAGE,prefix='MARRIAGE')\n",
    "dfsub1 = pd.concat((df,tmp_df_1,tmp_df_2),axis=1)\n",
    "#Drop variables for which we used one-hot encoding\n",
    "del dfsub1['EDUCATION']\n",
    "del dfsub1['MARRIAGE']\n",
    "\n",
    "\n",
    "split = np.random.rand(len(dfsub1)) < 0.8\n",
    "\n",
    "df_train = dfsub1[split]\n",
    "df_test = dfsub1[~split]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# fit training for scaling after upsampling\n",
    "X_train = df_train.drop(columns=['default']).values     \n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "\n",
    "print(\"Dimensions of training data \" , df_train.shape)\n",
    "print(\"Dimensions of test are \" , df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 1 to 30000\n",
      "Data columns (total 23 columns):\n",
      "SEX              30000 non-null int64\n",
      "AGE              30000 non-null int64\n",
      "default          30000 non-null int64\n",
      "PAY_0            30000 non-null int64\n",
      "PAY_2            30000 non-null int64\n",
      "PAY_3            30000 non-null int64\n",
      "PAY_4            30000 non-null int64\n",
      "PAY_5            30000 non-null int64\n",
      "PAY_6            30000 non-null int64\n",
      "log_LIMIT_BAL    30000 non-null float64\n",
      "log_PAY_AMT1     30000 non-null float64\n",
      "log_PAY_AMT2     30000 non-null float64\n",
      "log_PAY_AMT3     30000 non-null float64\n",
      "log_PAY_AMT4     30000 non-null float64\n",
      "log_PAY_AMT5     30000 non-null float64\n",
      "log_PAY_AMT6     30000 non-null float64\n",
      "EDUCATION_1      30000 non-null uint8\n",
      "EDUCATION_2      30000 non-null uint8\n",
      "EDUCATION_3      30000 non-null uint8\n",
      "EDUCATION_4      30000 non-null uint8\n",
      "MARRIAGE_1       30000 non-null uint8\n",
      "MARRIAGE_2       30000 non-null uint8\n",
      "MARRIAGE_3       30000 non-null uint8\n",
      "dtypes: float64(7), int64(9), uint8(7)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "dfsub1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2\n",
    "\n",
    "\n",
    "###  Field Definitions:\n",
    "\n",
    "- The items in the final data set are shown below.\n",
    "- Monetary amounts are in New Taiwanese dollars ($)\n",
    "\n",
    "\n",
    "- SEX\n",
    "     -  1 = Male\n",
    "     -  2 = Female\n",
    "        \n",
    "\n",
    "- AGE = Credit Card holder age in years\n",
    "\n",
    "\n",
    "- default:   Whether or not the customer defaulted (Target for predicting default)\n",
    "\n",
    "    \n",
    "- Payment history (2005)\n",
    "     - PAY_0 = September\n",
    "     - PAY_2 = August\n",
    "     - PAY_3 = July\n",
    "     - PAY_4 = June\n",
    "     - PAY_5 = May\n",
    "     - PAY_6 = April\n",
    "          -  -1 = payment received on time\n",
    "          -   1 = payment received one month late\n",
    "          -   2 = payment received two months late\n",
    "          -   \"......\"\n",
    "          -   9 = payment received nine months late or more\n",
    "         \n",
    "\n",
    "- log_LIMIT_BAL:  Natural log of the Credit Limit (max amount of credit allowed) \n",
    "\n",
    "    \n",
    "- log_PAY_AMT:  Natural log of the amount paid by month + $1\n",
    "     - log_PAY_AMT1 = September\n",
    "     - log_PAY_AMT2 = August\n",
    "     - log_PAY_AMT3 = July\n",
    "     - log_PAY_AMT4 = June\n",
    "     - log_PAY_AMT5 = May\n",
    "     - log_PAY_AMT6 = April\n",
    "\n",
    "    \n",
    " - EDUCATION (One-Hot Encoded when Predicting Default.  Used in the form below when used as target.)\n",
    "     - EDUCATION_1 = Graduate School\n",
    "     - EDUCATION_2 = University\n",
    "     - EDUCATION_3 = High School\n",
    "     - EDUCATION_4 = Other\n",
    "\n",
    "        \n",
    " - EDUCATION (This variable appears only as the target only when predicting Education.  Not one-hot encoded.)\n",
    "     - 1 = Graduate School\n",
    "     - 2 = University\n",
    "     - 3 = High School\n",
    "     - 4 = Other\n",
    "\n",
    "        \n",
    " - MARRIAGE (One-Hot Encoded)\n",
    "     - MARRIAGE_1 = Married\n",
    "     - MARRIAGE_2 = Single\n",
    "     - MARRIAGE_3 = Other\n",
    "    \n",
    "    \n",
    "###  OverSampling:\n",
    "\n",
    "Due to class imbalance in the Default variable, we oversampled the Default variable for Vaulue = 1 to create a balnced Traing set.\n",
    "The Test set was not re-sampled.\n",
    "\n",
    "### Scaling:\n",
    "\n",
    "Explanatory variables have been standard-scaled in Test and Train sets for both Modeling Objectives.  (Default and Education)\n",
    "\n",
    "### Excluded Fields:\n",
    "\n",
    "Data elements related to Amounts Billed by month were included in the original data set, but excluded here.  This is because the Exploratory analysis from earlier work indicated high correlation with Payment Amount, yet the Amount Billed had less explanatory value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 1 to 30000\n",
      "Data columns (total 19 columns):\n",
      "SEX              30000 non-null int64\n",
      "AGE              30000 non-null int64\n",
      "default          30000 non-null int64\n",
      "PAY_0            30000 non-null int64\n",
      "PAY_2            30000 non-null int64\n",
      "PAY_3            30000 non-null int64\n",
      "PAY_4            30000 non-null int64\n",
      "PAY_5            30000 non-null int64\n",
      "PAY_6            30000 non-null int64\n",
      "log_LIMIT_BAL    30000 non-null float64\n",
      "log_PAY_AMT1     30000 non-null float64\n",
      "log_PAY_AMT2     30000 non-null float64\n",
      "log_PAY_AMT3     30000 non-null float64\n",
      "log_PAY_AMT4     30000 non-null float64\n",
      "log_PAY_AMT5     30000 non-null float64\n",
      "log_PAY_AMT6     30000 non-null float64\n",
      "MARRIAGE_1       30000 non-null uint8\n",
      "MARRIAGE_2       30000 non-null uint8\n",
      "MARRIAGE_3       30000 non-null uint8\n",
      "dtypes: float64(7), int64(9), uint8(3)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "# perform one-hot encoding of the categorical data \"EDUCATION\" and \"MARRIAGE\".\n",
    "tmp_df_2 = pd.get_dummies(df.MARRIAGE,prefix='MARRIAGE')\n",
    "dfsub2 = pd.concat((df,tmp_df_2),axis=1)\n",
    "del dfsub2['MARRIAGE']\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'default' in dfsub2:\n",
    "    y = dfsub2['EDUCATION'].values # get the labels we want\n",
    "    del dfsub2['EDUCATION'] # get rid of the class label\n",
    "    X = dfsub2.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 5\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "dfsub2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1\n",
    "\n",
    "The choice of evaluation metric should consider the purpose for which the projects are undertaken.  Our objective with this data set is to predict two variables:\n",
    "\n",
    "    1) Whether a given customer defaults or not, and \n",
    "    2) The level of Education for a given customer.\n",
    "    \n",
    "- Predicting whether a customer will default.\n",
    "\n",
    "A cleint may use this model to determine which customer-facing strategies to deploy for a given customer.  If a customer is expected to default, there should be a more intesive collection strategy, and management of credit lines should be more conservative.  While such strategies are designed to limit losses from defaults, they may also lead to sub-optimal customer experiences for those who do not default.  Customers who are treated as likely to default are expected to attrit if they do not default.\n",
    "\n",
    "Precision is therefore important.  Low precision would lead to higher customer attrition.  Recall is also important.  Low Recall represents missed opportunity to apply loss-mitigation strategies to customer who need them, and will result in high default costs.\n",
    "\n",
    "Since balancing these two factors is important, we will choose F1 as the evaluation metric for this suite of models. \n",
    "\n",
    "- Predicting Education\n",
    "\n",
    "One use for this suite of models is to apply marketing strategies for other products to these demographic groups if the customer does not provide the information.\n",
    "\n",
    "The evaluation metric should again consider a balance between Recall and Precision.  Low Recall again represents a missed opportunity to apply a more targeted strategy, and low Precision would result in the wrong strategy applied to a given prospect.  \n",
    "Applying the wrong strategy can be expected to decrease the credibility of the business in the customer's view, and may make the customer less likely to respond to other offers.\n",
    "\n",
    "Since F1 considers both, we will choose it as the evaluation metric for this as well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling and Evaluation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling and Evaluation 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling and Evaluation 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exceptional Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
