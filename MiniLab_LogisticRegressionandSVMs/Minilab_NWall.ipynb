{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Lab Logistic Regression & SVMs\n",
    "Authors: Dan Davieau, Paul Panek, Olga Tanyuk, Nathan Wall\n",
    "\n",
    "The analysis below is to develop several models to predict the probablity of default for credit card customers.We will be focusing on logistic regression and SVM models using various options in sklearn. \n",
    "\n",
    "In order to assess our model we will begin by reading in the data and performing some of the data transformations that we documented in Lab 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 29 columns):\n",
      "ID                   30000 non-null int64\n",
      "LIMIT_BAL            30000 non-null float64\n",
      "SEX                  30000 non-null int64\n",
      "EDUCATION            30000 non-null int64\n",
      "MARRIAGE             30000 non-null int64\n",
      "AGE                  30000 non-null int64\n",
      "PAY_0                30000 non-null int32\n",
      "PAY_2                30000 non-null int32\n",
      "PAY_3                30000 non-null int32\n",
      "PAY_4                30000 non-null int32\n",
      "PAY_5                30000 non-null int32\n",
      "PAY_6                30000 non-null int32\n",
      "BILL_AMT1            30000 non-null float64\n",
      "BILL_AMT2            30000 non-null float64\n",
      "BILL_AMT3            30000 non-null float64\n",
      "BILL_AMT4            30000 non-null float64\n",
      "BILL_AMT5            30000 non-null float64\n",
      "BILL_AMT6            30000 non-null float64\n",
      "PAY_AMT1             30000 non-null float64\n",
      "PAY_AMT2             30000 non-null float64\n",
      "PAY_AMT3             30000 non-null float64\n",
      "PAY_AMT4             30000 non-null float64\n",
      "PAY_AMT5             30000 non-null float64\n",
      "PAY_AMT6             30000 non-null float64\n",
      "default              30000 non-null int64\n",
      "AGEGROUP             30000 non-null category\n",
      "TotalLatePayments    30000 non-null int64\n",
      "AvgBillAmt           30000 non-null float64\n",
      "AvgPayAmt            30000 non-null float64\n",
      "dtypes: category(1), float64(15), int32(6), int64(7)\n",
      "memory usage: 5.8 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "      <th>TotalLatePayments</th>\n",
       "      <th>AvgBillAmt</th>\n",
       "      <th>AvgPayAmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>11.663002</td>\n",
       "      <td>1.603733</td>\n",
       "      <td>1.842267</td>\n",
       "      <td>1.557267</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>0.104333</td>\n",
       "      <td>0.147000</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.116933</td>\n",
       "      <td>...</td>\n",
       "      <td>6.628429</td>\n",
       "      <td>6.560799</td>\n",
       "      <td>6.281239</td>\n",
       "      <td>6.075454</td>\n",
       "      <td>6.030313</td>\n",
       "      <td>5.931124</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.710133</td>\n",
       "      <td>8.624109</td>\n",
       "      <td>6.251226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8660.398374</td>\n",
       "      <td>0.941135</td>\n",
       "      <td>0.489129</td>\n",
       "      <td>0.744494</td>\n",
       "      <td>0.521405</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>0.305698</td>\n",
       "      <td>0.354112</td>\n",
       "      <td>0.347304</td>\n",
       "      <td>0.321346</td>\n",
       "      <td>...</td>\n",
       "      <td>3.252039</td>\n",
       "      <td>3.280914</td>\n",
       "      <td>3.351656</td>\n",
       "      <td>3.398790</td>\n",
       "      <td>3.445665</td>\n",
       "      <td>3.529484</td>\n",
       "      <td>0.415062</td>\n",
       "      <td>1.464712</td>\n",
       "      <td>3.123457</td>\n",
       "      <td>2.461844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7500.750000</td>\n",
       "      <td>10.819778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>6.725034</td>\n",
       "      <td>5.966147</td>\n",
       "      <td>5.690359</td>\n",
       "      <td>5.531405</td>\n",
       "      <td>4.768557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.107727</td>\n",
       "      <td>5.025010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>11.849398</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.649693</td>\n",
       "      <td>7.605392</td>\n",
       "      <td>7.495542</td>\n",
       "      <td>7.313220</td>\n",
       "      <td>7.313220</td>\n",
       "      <td>7.313220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.708304</td>\n",
       "      <td>6.924126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22500.250000</td>\n",
       "      <td>12.388394</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.518392</td>\n",
       "      <td>8.517193</td>\n",
       "      <td>8.412943</td>\n",
       "      <td>8.297357</td>\n",
       "      <td>8.301894</td>\n",
       "      <td>8.294050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.826377</td>\n",
       "      <td>8.032059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>13.815511</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.680323</td>\n",
       "      <td>14.336836</td>\n",
       "      <td>13.705740</td>\n",
       "      <td>13.339086</td>\n",
       "      <td>12.963436</td>\n",
       "      <td>13.178112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.664303</td>\n",
       "      <td>12.752655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID     LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean   15000.500000     11.663002      1.603733      1.842267      1.557267   \n",
       "std     8660.398374      0.941135      0.489129      0.744494      0.521405   \n",
       "min        1.000000      9.210340      1.000000      1.000000      1.000000   \n",
       "25%     7500.750000     10.819778      1.000000      1.000000      1.000000   \n",
       "50%    15000.500000     11.849398      2.000000      2.000000      2.000000   \n",
       "75%    22500.250000     12.388394      2.000000      2.000000      2.000000   \n",
       "max    30000.000000     13.815511      2.000000      4.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean      35.485500      0.104333      0.147000      0.140300      0.116933   \n",
       "std        9.217904      0.305698      0.354112      0.347304      0.321346   \n",
       "min       21.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       28.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ...           PAY_AMT1      PAY_AMT2      PAY_AMT3      PAY_AMT4  \\\n",
       "count      ...       30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean       ...           6.628429      6.560799      6.281239      6.075454   \n",
       "std        ...           3.252039      3.280914      3.351656      3.398790   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           6.907755      6.725034      5.966147      5.690359   \n",
       "50%        ...           7.649693      7.605392      7.495542      7.313220   \n",
       "75%        ...           8.518392      8.517193      8.412943      8.297357   \n",
       "max        ...          13.680323     14.336836     13.705740     13.339086   \n",
       "\n",
       "           PAY_AMT5      PAY_AMT6       default  TotalLatePayments  \\\n",
       "count  30000.000000  30000.000000  30000.000000       30000.000000   \n",
       "mean       6.030313      5.931124      0.221200           0.710133   \n",
       "std        3.445665      3.529484      0.415062           1.464712   \n",
       "min        0.000000      0.000000      0.000000           0.000000   \n",
       "25%        5.531405      4.768557      0.000000           0.000000   \n",
       "50%        7.313220      7.313220      0.000000           0.000000   \n",
       "75%        8.301894      8.294050      0.000000           1.000000   \n",
       "max       12.963436     13.178112      1.000000           6.000000   \n",
       "\n",
       "         AvgBillAmt     AvgPayAmt  \n",
       "count  30000.000000  30000.000000  \n",
       "mean       8.624109      6.251226  \n",
       "std        3.123457      2.461844  \n",
       "min        0.000000      0.000000  \n",
       "25%        7.107727      5.025010  \n",
       "50%        9.708304      6.924126  \n",
       "75%       10.826377      8.032059  \n",
       "max       13.664303     12.752655  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read the data in\n",
    "df = pd.read_csv('C:/Users/bsnxw01/Desktop/MSDS_Program/MSDS_7331/Project/Lab1/DataMiningGroupProjects/Project1/Input/DefaultCreditcardClients.csv')\n",
    "\n",
    "#convert default to default name\n",
    "df.rename(columns={'default payment next month':'default'}, inplace=True)\n",
    "\n",
    "#convert any non-identified education categories to 'OTHER'\n",
    "df['EDUCATION'] = df['EDUCATION'].replace(to_replace=(0,5,6),value=4)\n",
    "\n",
    "#convert any non-identified marriage categories to 'OTHER'\n",
    "df['MARRIAGE'] = df['MARRIAGE'].replace(to_replace=(0),value=3)\n",
    "\n",
    "#transform continuous variables as they each have a mostly exponential distribution\n",
    "continuous_features = ['LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2','BILL_AMT3',\n",
    "                       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "                       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
    "                       'PAY_AMT6']\n",
    "# assign zero to na to not get error on log transform then assign the zero values back to zero\n",
    "df[continuous_features] = df[continuous_features].replace(to_replace=0,value=np.nan).apply(np.log).replace(to_replace=np.nan,value=0)\n",
    "\n",
    "#bin the ages based on various age groups \n",
    "bins = [18, 25, 35, 45, 55, 65, 100]\n",
    "labels = [0,1,2,3,4,5]\n",
    "df['AGEGROUP'] = pd.cut(df['AGE'], bins=bins, labels=labels)\n",
    "\n",
    "#flag all the payment histor to late vs not late\n",
    "payments = ['PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6']\n",
    "bins = [-10, 1, 10]\n",
    "labels = [0,1]\n",
    "for fi,feature in enumerate(payments):\n",
    "    df[feature] = pd.cut(df[feature], bins=bins, labels=labels).astype(np.int)\n",
    "#count how many total late payments have been made\n",
    "df['TotalLatePayments'] = df[payments].sum(axis=1)\n",
    "\n",
    "#get the avg bill amt\n",
    "bill_amt = ['BILL_AMT1', 'BILL_AMT2','BILL_AMT3','BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n",
    "df['AvgBillAmt'] = df[bill_amt].mean(axis=1)\n",
    "\n",
    "#get the avg pay amt\n",
    "pay_amt = ['PAY_AMT1','PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5','PAY_AMT6']\n",
    "df['AvgPayAmt'] = df[pay_amt].mean(axis=1)\n",
    "\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding the categorical data\n",
    "From above we are able to see that we 31 features of mixed type (categorical & continuous) that we will be using to predict our the class of our target, \"default\". In order to use the categorical variables we will encode them using one hot encoding.\n",
    "\n",
    "For this we will be encoding Education, Marriage, Agegroup, Pay_0-Pay_6. Sex does not need encoded as there are only 2 categories.\n",
    "\n",
    "_*We will will also go ahead and remove the ID variable as it won't be used in our predictions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    21620\n",
       "1.0     3494\n",
       "2.0     1567\n",
       "3.0     1073\n",
       "6.0      938\n",
       "4.0      711\n",
       "5.0      597\n",
       "Name: TotalLatePayments, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TotalLatePayments'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 21 columns):\n",
      "LIMIT_BAL            30000 non-null float64\n",
      "BILL_AMT1            30000 non-null float64\n",
      "PAY_AMT1             30000 non-null float64\n",
      "PAY_0                30000 non-null int32\n",
      "TotalLatePayments    30000 non-null int64\n",
      "AvgBillAmt           30000 non-null float64\n",
      "AvgPayAmt            30000 non-null float64\n",
      "EDUCATION_1          30000 non-null uint8\n",
      "EDUCATION_2          30000 non-null uint8\n",
      "EDUCATION_3          30000 non-null uint8\n",
      "EDUCATION_4          30000 non-null uint8\n",
      "MARRIAGE_1           30000 non-null uint8\n",
      "MARRIAGE_2           30000 non-null uint8\n",
      "MARRIAGE_3           30000 non-null uint8\n",
      "AGEGROUP_0           30000 non-null uint8\n",
      "AGEGROUP_1           30000 non-null uint8\n",
      "AGEGROUP_2           30000 non-null uint8\n",
      "AGEGROUP_3           30000 non-null uint8\n",
      "AGEGROUP_4           30000 non-null uint8\n",
      "AGEGROUP_5           30000 non-null uint8\n",
      "default              30000 non-null int64\n",
      "dtypes: float64(5), int32(1), int64(2), uint8(13)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Change numeric values to floats\n",
    "numVar = df[['LIMIT_BAL', 'BILL_AMT1','PAY_AMT1','PAY_0','TotalLatePayments','AvgBillAmt','AvgPayAmt']]\n",
    "\n",
    "targetVar = df['default']\n",
    "\n",
    "# One hot encodings the categorical variables\n",
    "charVar = ['EDUCATION', 'MARRIAGE','AGEGROUP']\n",
    "tmp_df = pd.get_dummies(df[charVar].astype('category'))\n",
    "\n",
    "df = pd.concat((numVar, tmp_df, targetVar),axis=1) # add back into the dataframe\n",
    "\n",
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the training/test data set\n",
    "\n",
    "After encoding the data we now have 96 features that we will be using to predict our the class of our target, \"default\". There are 30,000 observations in this dataset that we split into training/test sets (80/20 split) that we can use to assess the performance of our two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training features are  (24000, 20)\n",
      "Dimensions of training target are  (24000,)\n",
      "Dimensions of testing features are  (6000, 20)\n",
      "Dimensions of testing target are  (6000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'default' in df:\n",
    "    y = df['default'].values # get the labels we want\n",
    "    del df['default'] # get rid of the class label\n",
    "    X = df.values # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "      \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "print(\"Dimensions of training features are \" , X_train.shape)\n",
    "print(\"Dimensions of training target are \" , y_train.shape)\n",
    "print(\"Dimensions of testing features are \" , X_test.shape)\n",
    "print(\"Dimensions of testing target are \" , y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the data\n",
    "From above we see that we succesfully split our training/test sets split up 80/20 with 24000 obs in the training data and 6000 in our test set.\n",
    "\n",
    "Once we have our datasets split up we can now use our training data to calculate the mean & standard deviation to scale our continuous variables. It is important to not let the values from the test data be used in the calculation of the mean & standard deviation as this may accidently provide you insights into the test data that you should not have in your model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the Logistic Regression Model\n",
    "After we scale our train & test sets we can start training our models. We will begin by training the Logisitc Regression model and explore the various options to assess the models performance.\n",
    "\n",
    "Our first logistic model will begin by using the default logistic regression paramertes from the scikitlearns logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8173333333333334\n",
      "confusion matrix\n",
      " [[4501  179]\n",
      " [ 917  403]]\n",
      "EDUCATION_4 has weight of -0.5266471149784026\n",
      "LIMIT_BAL has weight of -0.18513351186934404\n",
      "AvgPayAmt has weight of -0.175310093321993\n",
      "BILL_AMT1 has weight of -0.06428842862794766\n",
      "PAY_AMT1 has weight of -0.03399916666420435\n",
      "AGEGROUP_1 has weight of 0.0064036624302471635\n",
      "AGEGROUP_0 has weight of 0.07444017456230266\n",
      "AGEGROUP_2 has weight of 0.09033530903861028\n",
      "AvgBillAmt has weight of 0.10749524956242282\n",
      "MARRIAGE_2 has weight of 0.14231760073698624\n",
      "AGEGROUP_4 has weight of 0.15051655139977083\n",
      "AGEGROUP_5 has weight of 0.16702233214254109\n",
      "AGEGROUP_3 has weight of 0.1734468783332037\n",
      "MARRIAGE_3 has weight of 0.22412377229084582\n",
      "TotalLatePayments has weight of 0.24811934216025905\n",
      "MARRIAGE_1 has weight of 0.2957235348784709\n",
      "EDUCATION_3 has weight of 0.3271879367380568\n",
      "EDUCATION_1 has weight of 0.4136649754322847\n",
      "EDUCATION_2 has weight of 0.44795911071419503\n",
      "PAY_0 has weight of 1.5617068001476622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "lr = LogisticRegression() # get object\n",
    "# train the reusable logisitc regression model on the training data\n",
    "lr.fit(X_train,y_train)  # train object\n",
    "y_hat = lr.predict(X_test) # get test set precitions\n",
    "\n",
    "# now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print(\"accuracy\", acc )\n",
    "print(\"confusion matrix\\n\",conf)\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr.coef_.T,df.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out\n",
    "    \n",
    "weights = pd.Series(lr.coef_[0],index=df.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
