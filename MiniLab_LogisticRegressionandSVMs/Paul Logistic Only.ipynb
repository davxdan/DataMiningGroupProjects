{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Lab 1\n",
    "Daniel Davieau, Nathan Wall, Olga Tanyuk and Paul Panek\n",
    "\n",
    "#### Project Review\n",
    "\n",
    "The purpose of this data set is to predict whether or not individual credit card clients (in Taiwan) will default.\n",
    "\n",
    "The primary explanatory variables include:\n",
    "- Six months of Payment Amounts, Billed Amounts and the Timeliness of each Payment.\n",
    "- Demographic information: Marital Status, Sex, Age and Level of Education.\n",
    "    \n",
    "A description of all variables in the data set is provided in the last cell of this notebook for reference.\n",
    "\n",
    "##### Data Preparation and Transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('data/DefaultCreditcardClients.csv')\n",
    "df.rename(columns={'default payment next month':'default'}, inplace=True)\n",
    "\n",
    "#set index to the \"ID\" value and remove the ID column\n",
    "df.index = df.ID\n",
    "del df['ID']\n",
    "\n",
    "#Create Lists for Analysis\n",
    "continuous_features = ['LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2','BILL_AMT3',\n",
    "                       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
    "                       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5',\n",
    "                       'PAY_AMT6']\n",
    "ordinal_features = ['EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0','PAY_2', 'PAY_3',\n",
    "                    'PAY_4', 'PAY_5', 'PAY_6','default']\n",
    "\n",
    "#Convert datatypes\n",
    "df[continuous_features] = df[continuous_features].astype(np.float64)\n",
    "df[ordinal_features] = df[ordinal_features].astype(np.int64)\n",
    "\n",
    "#convert any non-identified education categories to 'OTHER'\n",
    "df['EDUCATION'] = df['EDUCATION'].replace(to_replace=(0,5,6),value=4)\n",
    "\n",
    "#convert any non-identified marriage categories to 'OTHER'\n",
    "df['MARRIAGE'] = df['MARRIAGE'].replace(to_replace=(0),value=3)\n",
    "\n",
    "#Log transform continuous variables; as they each have a mostly \n",
    "##exponential distribution\n",
    "df[\"log_LIMIT_BAL\"]=np.log(df.LIMIT_BAL)\n",
    "df[\"log_PAY_AMT1\"]=np.log(df.PAY_AMT1+1)\n",
    "df[\"log_PAY_AMT2\"]=np.log(df.PAY_AMT2+1)\n",
    "df[\"log_PAY_AMT3\"]=np.log(df.PAY_AMT3+1)\n",
    "df[\"log_PAY_AMT4\"]=np.log(df.PAY_AMT4+1)\n",
    "df[\"log_PAY_AMT5\"]=np.log(df.PAY_AMT5+1)\n",
    "df[\"log_PAY_AMT6\"]=np.log(df.PAY_AMT6+1)\n",
    "\n",
    "\n",
    "# One-hot encoding of \"EDUCATION\" and \"MARRIAGE\".\n",
    "tmp_df_1 = pd.get_dummies(df.EDUCATION,prefix='EDUCATION')\n",
    "tmp_df_2 = pd.get_dummies(df.MARRIAGE,prefix='MARRIAGE')\n",
    "df = pd.concat((df,tmp_df_1,tmp_df_2),axis=1)\n",
    "\n",
    "#Create a separate dataset in case we need to come back to original\n",
    "dfsub = df.copy()\n",
    "#dfsub = pd.concat((df,tmp_df_1,tmp_df_2),axis=1)\n",
    "\n",
    "#We will not need these attributes. We are using log of them instead.\n",
    "del dfsub['LIMIT_BAL']\n",
    "del dfsub['PAY_AMT1']\n",
    "del dfsub['PAY_AMT2']\n",
    "del dfsub['PAY_AMT3']\n",
    "del dfsub['PAY_AMT4']\n",
    "del dfsub['PAY_AMT5']\n",
    "del dfsub['PAY_AMT6']\n",
    "\n",
    "#We found in Lab1 that there is high correlation between BILL Amount and Pay \n",
    "##Amounts so ignore bill amount for now\n",
    "del dfsub['BILL_AMT1']\n",
    "del dfsub['BILL_AMT2']\n",
    "del dfsub['BILL_AMT3']\n",
    "del dfsub['BILL_AMT4']\n",
    "del dfsub['BILL_AMT5']\n",
    "del dfsub['BILL_AMT6']\n",
    "\n",
    "#Drop variables for which we used one-hot encoding\n",
    "del dfsub['EDUCATION']\n",
    "del dfsub['MARRIAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 1 to 30000\n",
      "Data columns (total 23 columns):\n",
      "SEX              30000 non-null int64\n",
      "AGE              30000 non-null int64\n",
      "PAY_0            30000 non-null int64\n",
      "PAY_2            30000 non-null int64\n",
      "PAY_3            30000 non-null int64\n",
      "PAY_4            30000 non-null int64\n",
      "PAY_5            30000 non-null int64\n",
      "PAY_6            30000 non-null int64\n",
      "default          30000 non-null int64\n",
      "log_LIMIT_BAL    30000 non-null float64\n",
      "log_PAY_AMT1     30000 non-null float64\n",
      "log_PAY_AMT2     30000 non-null float64\n",
      "log_PAY_AMT3     30000 non-null float64\n",
      "log_PAY_AMT4     30000 non-null float64\n",
      "log_PAY_AMT5     30000 non-null float64\n",
      "log_PAY_AMT6     30000 non-null float64\n",
      "EDUCATION_1      30000 non-null uint8\n",
      "EDUCATION_2      30000 non-null uint8\n",
      "EDUCATION_3      30000 non-null uint8\n",
      "EDUCATION_4      30000 non-null uint8\n",
      "MARRIAGE_1       30000 non-null uint8\n",
      "MARRIAGE_2       30000 non-null uint8\n",
      "MARRIAGE_3       30000 non-null uint8\n",
      "dtypes: float64(7), int64(9), uint8(7)\n",
      "memory usage: 4.1 MB\n"
     ]
    }
   ],
   "source": [
    "dfsub.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paul Comments:  \n",
    "\n",
    "#### In the cell above i changed dfsub = df to dfsub = df.copy()   - without the copy(), it wasn't keepig the original set.\n",
    "\n",
    "#### In the cell below, I added a seed to the ShuffleSplit by adding random_state=0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "#Isolate the \"default\" variable into y and keep everythign else in X to use for predictions:\n",
    "if 'default' in dfsub:\n",
    "    y = dfsub['default'].values\n",
    "    del dfsub['default'] \n",
    "    X = dfsub.values\n",
    "\n",
    "#Create a reuseable cv_object:  Random State keeps the seed.\n",
    "num_cv_iterations = 10\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits=num_cv_iterations,test_size  = 0.2,random_state=0)\n",
    "\n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8126666666666666\n",
      "[[4534  179]\n",
      " [ 945  342]]\n",
      "log_PAY_AMT1 has weight of -0.1807909712200579\n",
      "log_PAY_AMT3 has weight of -0.16150368469918397\n",
      "EDUCATION_4 has weight of -0.13477120833523076\n",
      "log_LIMIT_BAL has weight of -0.1344163816867008\n",
      "log_PAY_AMT2 has weight of -0.12031113408502857\n",
      "log_PAY_AMT4 has weight of -0.11991702387361629\n",
      "SEX has weight of -0.04916837255181689\n",
      "MARRIAGE_2 has weight of -0.041628652006493246\n",
      "log_PAY_AMT6 has weight of -0.03842323703413686\n",
      "log_PAY_AMT5 has weight of -0.037378558263821124\n",
      "MARRIAGE_3 has weight of -0.018674079818716403\n",
      "EDUCATION_3 has weight of -0.004393087552692627\n",
      "EDUCATION_2 has weight of 0.0071617032071382095\n",
      "PAY_4 has weight of 0.028147326180670777\n",
      "EDUCATION_1 has weight of 0.031269711563942815\n",
      "MARRIAGE_1 has weight of 0.045858186508005605\n",
      "PAY_2 has weight of 0.04656442628792501\n",
      "AGE has weight of 0.050218582144257645\n",
      "PAY_5 has weight of 0.10333476027718924\n",
      "PAY_6 has weight of 0.11501155541006708\n",
      "PAY_3 has weight of 0.12806157029791332\n",
      "PAY_0 has weight of 0.5392469996509014\n"
     ]
    }
   ],
   "source": [
    "###  I THINK this is still using the internal CV ....\n",
    "# Went directly to the case using standardScaler.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Train and test data set variables:\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train)\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model\n",
    "lr_clf = LogisticRegression(penalty='l2', C=.05) \n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and print\n",
    "zip_vars = zip(lr_clf.coef_.T,dfsub.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model Quality: \n",
    "\n",
    "At initial tuning levels, while the accuracy of this model is more than 81%, performance is not acceptable.\n",
    "- Accuracy is similar to the overall share of Negative cases in the set.\n",
    "- Specificity (True Negatives/Total Actual Negatives) is 96%, but\n",
    "- Sensitivity/Recall (True Positives/Total Actual Positives) is only 27%.\n",
    "- Precision:  Only 66% of the predicted positives were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.05 Class_Weight=None\n",
      "accuracy: 0.8126666666666666\n",
      "[[4534  179]\n",
      " [ 945  342]]\n",
      "C= 1.0 Class_Weight=None\n",
      "accuracy: 0.8126666666666666\n",
      "[[4534  179]\n",
      " [ 945  342]]\n",
      "C= 20.0 Class_Weight=None\n",
      "accuracy: 0.8126666666666666\n",
      "[[4534  179]\n",
      " [ 945  342]]\n",
      "C= 0.05 Class_Weight=balanced\n",
      "accuracy: 0.7281666666666666\n",
      "[[3560 1153]\n",
      " [ 478  809]]\n",
      "C= 1.0 Class_Weight=balanced\n",
      "accuracy: 0.7285\n",
      "[[3563 1150]\n",
      " [ 479  808]]\n",
      "C= 20.0 Class_Weight=balanced\n",
      "accuracy: 0.7285\n",
      "[[3563 1150]\n",
      " [ 479  808]]\n"
     ]
    }
   ],
   "source": [
    "# Setting three alternatives for C\n",
    "Param = [.05,1.0,20.0]\n",
    "\n",
    "for z in Param:\n",
    "    lr_clf = LogisticRegression(penalty='l2', C=z, class_weight=None) \n",
    "    lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "    print('C=', z, 'Class_Weight=None')\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )\n",
    "    \n",
    "for z in Param:\n",
    "    lr_clf = LogisticRegression(penalty='l2', C=z, class_weight='balanced') \n",
    "    lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "    y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "    print('C=', z, 'Class_Weight=balanced')\n",
    "    print('accuracy:', acc )\n",
    "    print(conf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning\n",
    "\n",
    "Impact of tuning C is negligible.  The number of True and False Negatives is unchanged, and the number of True and False positives only changed by one.\n",
    "Impact on overall accuracy was negligible as well.\n",
    "\n",
    "Impact of using standard scaler vs not using it (not shown) was also very small.\n",
    "\n",
    "Using balanced Class_Weight does change performance.\n",
    "- Accuracy drops to just under 73%.\n",
    "- Precision drops to 41% from 66%.\n",
    "- Specificity drops to 76% from 96%, but\n",
    "- Recall increases to 63% from 27%.\n",
    "\n",
    "Even though the Recall increases, it still does not seem reasonable, and the other measures degrade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAE6CAYAAAD+0VK4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XlcVPX+P/DXwKhouMAgIEqpqJcW\nSwk3NE0lH90eN6+3W6FlmfqtvGKuieWKC4lL8ii1DdFMzS9lpaVlOpmajHJx16t+bVzKBUU2FRFZ\n5vz+8Me5DMzGfA4cxvN6Ph48HnPmnPf5fD5zPrznzOdsOkmSJBARkaZ4qV0BIiKqfUz+REQaxORP\nRKRBTP5ERBrE5E9EpEFM/kREGsTkT0SkQUz+REQaxORPRKRBTP5ERBqkV7sCjly+fNnuvICAAGRn\nZ7u1XrVi1SybbfaMWDXLZps9I9ZZfEhIiEvr4J4/EZEGMfkTEWmQIsM+hw8fxqpVq2CxWNC/f38M\nGjTIav7OnTuxZs0a+Pv7AwCefvpp9O/fX4miiYjIDcLJ32KxICUlBdOnT4fBYMC7776LyMhItGrV\nymq5qKgojBw5UrQ4IiJSgPCwj9lsRnBwMIKCgqDX6xEVFYWMjAwl6kZERDVEeM8/NzcXBoNBnjYY\nDPj999+rLJeeno6TJ0+iRYsWGDZsGAICAkSLJiIiN+lEn+S1d+9eHDlyBKNGjQIA7N69G2azGSNG\njJCXuXnzJnx8fFCvXj1s27YNe/fuxaxZs6qsy2g0wmg0AgASExNRXFxst1y9Xo/S0lK36qxWrJpl\ns82eEatm2WyzZ8Q6i69fv75r63C79P/PYDAgJydHns7JyYGfn5/VMo0bN5ZfR0dHY926dTbXFR0d\njejoaHna0Xmw9+L5ufdirJple2KsmmWzzZ4R6yze1fP8hZN/WFgYMjMzkZWVBX9/f5hMJowdO9Zq\nmby8PPkLYf/+/VUOBrui7PWBVtNXK833Tv6+2uskItIq4eTv7e2NESNGICEhARaLBX379kVoaChS\nU1MRFhaGyMhI/PTTT9i/fz+8vb3h6+uL0aNHK1F3IiJykyLn+UdERCAiIsLqvZiYGPn1Sy+9hJde\nekmJooiISAG8wpeISIOY/ImINIjJn4hIg5j8iYg0iMmfiEiDmPyJiDSIyZ+ISIOY/ImINIjJn4hI\ng5j8iYg0iMmfiEiDmPyJiDSIyZ+ISIOY/ImINIjJn4hIg5j8iYg0iMmfiEiDmPyJiDRIkeR/+PBh\njBs3Dm+99RY2btxod7l9+/bhxRdfxJkzZ5QoloiI3CSc/C0WC1JSUjB16lQkJSUhLS0NFy9erLLc\n7du38dNPP6F9+/aiRRIRkSDh5G82mxEcHIygoCDo9XpERUUhIyOjynKpqakYOHAg6tWrJ1okEREJ\nEk7+ubm5MBgM8rTBYEBubq7VMufOnUN2djYef/xx0eKIiEgBetEVSJJU5T2dTie/tlgsWL16NUaP\nHu10XUajEUajEQCQmJiIgIAAed5VJ7EVl3VGr9dXa3mlYtUsm232jFg1y2abPSNWiXhAgeRvMBiQ\nk5MjT+fk5MDPz0+eLioqwoULFzB79mwAQH5+PhYuXIi4uDiEhYVZrSs6OhrR0dHydHZ2tsv1qM6y\nAQEB1VpeqVg1y2abPSNWzbLZZs+IdRYfEhLi0jqEk39YWBgyMzORlZUFf39/mEwmjB07Vp7fqFEj\npKSkyNPx8fF45ZVXqiR+IiKqPcLJ39vbGyNGjEBCQgIsFgv69u2L0NBQpKamIiwsDJGRkUrUk4iI\nFCSc/AEgIiICERERVu/FxMTYXDY+Pl6JIomISACv8CUi0iAmfyIiDWLyJyLSICZ/IiINYvInItIg\nJn8iIg1i8ici0iAmfyIiDWLyJyLSICZ/IiINYvInItIgJn8iIg1i8ici0iAmfyIiDWLyJyLSICZ/\nIiINYvInItIgJn8iIg1i8ici0iBFnuF7+PBhrFq1ChaLBf3798egQYOs5m/btg0///wzvLy84OPj\ngzfffBOtWrVSomgiInKDcPK3WCxISUnB9OnTYTAY8O677yIyMtIquffq1QsDBgwAAOzfvx+rV6/G\ntGnTRIsmIiI3CQ/7mM1mBAcHIygoCHq9HlFRUcjIyLBaplGjRvLroqIi6HQ60WKJiEiA8J5/bm4u\nDAaDPG0wGPD7779XWW7r1q3YsmULSktLMXPmTNFiiYhIgE6SJElkBXv37sWRI0cwatQoAMDu3bth\nNpsxYsQIm8vv2bMHhw8fxpgxY6rMMxqNMBqNAIDExEQUFxfL867+I8phPYK+M7lcZ71ej9LSUpeX\nVypWzbLZZs+IVbNsttkzYp3F169f37V1uF36/2cwGJCTkyNP5+TkwM/Pz+7yUVFRSE5OtjkvOjoa\n0dHR8nR2drbL9ajOsgEBAdVaXqlYNctmmz0jVs2y2WbPiHUWHxIS4tI6hMf8w8LCkJmZiaysLJSW\nlsJkMiEyMtJqmczMTPn1wYMH0aJFC9FiiYhIgPCev7e3N0aMGIGEhARYLBb07dsXoaGhSE1NRVhY\nGCIjI7F161YcO3YM3t7e8PX1RWxsrBJ1JyIiNylynn9ERAQiIiKs3ouJiZFfDx8+XIliiIhIIbzC\nl4hIg5j8iYg0iMmfiEiDmPyJiDSIyZ+ISIOY/ImINIjJn4hIg5j8iYg0iMmfiEiDmPyJiDSIyZ+I\nSIOY/ImINIjJn4hIg5j8iYg0iMmfiEiDmPyJiDSIyZ+ISIOY/ImINEiRxzgePnwYq1atgsViQf/+\n/TFo0CCr+Zs3b8Yvv/wCb29vNGnSBP/617/QvHlzJYomIiI3CO/5WywWpKSkYOrUqUhKSkJaWhou\nXrxotUzr1q2RmJiIxYsXo3v37li7dq1osUREJEA4+ZvNZgQHByMoKAh6vR5RUVHIyMiwWuaRRx5B\ngwYNAADt27dHbm6uaLFERCRAOPnn5ubCYDDI0waDwWFy37FjBzp16iRaLBERCRAe85ckqcp7Op3O\n5rK7d+/G2bNnER8fb3O+0WiE0WgEACQmJiIgIECed9VJPSou64xer6/W8krFqlk22+wZsWqWzTZ7\nRqwS8YACyd9gMCAnJ0eezsnJgZ+fX5Xljh49iu+++w7x8fGoV6+ezXVFR0cjOjpans7Ozna5HtVZ\nNiAgoFrLKxWrZtlss2fEqlk22+wZsc7iQ0JCXFqH8LBPWFgYMjMzkZWVhdLSUphMJkRGRlotc+7c\nOSQnJyMuLg5NmzYVLZKIiAQJ7/l7e3tjxIgRSEhIgMViQd++fREaGorU1FSEhYUhMjISa9euRVFR\nEZYsWQLg7rfWlClThCtPRETuUeQ8/4iICERERFi9FxMTI7+eMWOGEsUQEZFCeIUvEZEGMfkTEWkQ\nkz8RkQYx+RMRaRCTPxGRBjH5ExFpkCKnetZ1f193yuH8TS+H11JNiIjqBu75ExFpEJM/EZEGMfkT\nEWkQkz8RkQYx+RMRaRCTPxGRBjH5ExFpEJM/EZEGMfkTEWkQkz8RkQYx+RMRaRCTPxGRBilyY7fD\nhw9j1apVsFgs6N+/PwYNGmQ1/8SJE1i9ejX++OMPjB8/Ht27d1ei2FrzQ2p+hal8q3nPxjSr3coQ\nESlAeM/fYrEgJSUFU6dORVJSEtLS0nDx4kWrZQICAjB69Gj06tVLtDgiIlKA8J6/2WxGcHAwgoKC\nAABRUVHIyMhAq1at5GUCAwMBADqdTrQ4j/Phhx86nD927NhaqgkR0X8JJ//c3FwYDAZ52mAw4Pff\nf3drXUajEUajEQCQmJiIgIAAed5VJ7EVl60u57H5dueIlFvdeL1e73Z5asWqWbYnxqpZNtvsGbFK\nxAMKJH9Jkqq85+4efnR0NKKjo+Xp7Oxsl2Ors2xdia1ufEBAgNvlqRWrZtmeGKtm2WyzZ8Q6iw8J\nCXFpHcJj/gaDATk5OfJ0Tk4O/Pz8RFdLREQ1SDj5h4WFITMzE1lZWSgtLYXJZEJkZKQSdSMiohoi\nPOzj7e2NESNGICEhARaLBX379kVoaChSU1MRFhaGyMhImM1mLF68GLdu3cKBAwfw1VdfYcmSJUrU\nn4iI3KDIef4RERGIiIiwei8mJkZ+3a5dO3zyySdKFEVERArgFb5ERBrE5E9EpEFM/kREGsTkT0Sk\nQUz+REQaxORPRKRBTP5ERBqkyHn+VDMCze9av2EGAitMZrWbX6v1IaJ7B/f8iYg0iHv+96jU/7zi\ncH7Mw2tqqSZEVBdxz5+ISIOY/ImINIjJn4hIg5j8iYg0iMmfiEiDeLYP2RRy+Jj1dIXXlzt1dBhb\n9vpAq+mrFV57J3/vdqwr8UTkGu75ExFpEJM/EZEGKTLsc/jwYaxatQoWiwX9+/fHoEGDrOaXlJRg\n2bJlOHv2LBo3bozx48cjMDDQztqIiKimCSd/i8WClJQUTJ8+HQaDAe+++y4iIyPRqlUreZkdO3bg\nvvvuw9KlS5GWloZ169ZhwoQJokUTWfn7ulMO5296ObyWakJU9wkP+5jNZgQHByMoKAh6vR5RUVHI\nyMiwWmb//v148sknAQDdu3fH8ePHIUmSaNFEROQm4eSfm5sLg8EgTxsMBuTm5tpdxtvbG40aNcLN\nmzdFiyYiIjcJD/vY2oPX6XTVXgYAjEYjjEYjACAxMREBAQH/nfmdyWpZvV6P0tJSl+qYNq6X27EA\nMDz2v/WobuycOXPcLtsSkOwwNqByQAWxfX5yu1wAKI7u61a5AIS2lVrbedVyc6V38q2mhse2cxg/\nc+ZMu/Mq94HKvPa9bv1GhVt3W7onV1m+ouW7/upwfuV+UFF9469V3qt4Sm/FPmDL1X9E/fd1pXlB\nlbajo9jK8c5ie36wx+H8yv2gIpHt7GgbA9XczpVuzy6ynR1tY0eEk7/BYEBOTo48nZOTAz8/P5vL\nGAwGlJWVobCwEL6+vlXWFR0djejoaHk6OzvbbrkBAQEO5zuiVqyaZbPNjj0b08xhrEj7ncU6OvVB\npFxn8SF254iXrVasmmWrtZ0rx4aEONuydwkP+4SFhSEzMxNZWVkoLS2FyWRCZGSk1TKPP/44du7c\nCQDYt28fHn74YZt7/kREVDuE9/y9vb0xYsQIJCQkwGKxoG/fvggNDUVqairCwsIQGRmJfv36Ydmy\nZXjrrbfg6+uL8ePHK1F3IiJykyLn+UdERCAiIsLqvZiYGPl1/fr1MXHiRCWKIiIiBfDePkQKGDt2\nrPxa9BgJUW3g7R2IiDSIyZ+ISIOY/ImINIjJn4hIg3jAl0hlWe3mW01X54BxzMNr3I4lbWPyJ9Ko\nyk9k4xeHtnDYh4hIg5j8iYg0iMM+ROQW7+Tv5dccMvI83PMnItIgJn8iIg1i8ici0iAmfyIiDWLy\nJyLSICZ/IiINYvInItIgJn8iIg1i8ici0iChK3wLCgqQlJSEa9euoXnz5pgwYQJ8fX2rLJeQkIDf\nf/8d4eHheOedd0SKJCIiBQjt+W/cuBEdO3bEhx9+iI4dO2Ljxo02lxs4cCDGjBkjUhQRESlIKPln\nZGSgT58+AIA+ffogIyPD5nIdO3ZEw4YNRYoiIiIFCQ37XL9+HX5+fgAAPz8/3LhxQ6gyRqMRRqMR\nAJCYmIiAgAC7y+r1eofzHVErVs2y2WbPiFWz7NqMvepgnshn5zw+XyBWpFwAZpXKtcNp8p87dy7y\n86t+YIMHD3arQEeio6MRHR0tTzu6S6DIXQTVilWzbLbZM2LVLFvNNlckuh6R+JqMDaylckNCQlyK\nc5r8Z8yYYXde06ZNkZeXBz8/P+Tl5aFJkyYuFUpEROoSGvOPjIzErl27AAC7du1Cly5dFKkUERHV\nLKHkP2jQIBw9ehRjx47F0aNHMWjQIADAmTNn8Mknn8jLzZw5E0uWLMGxY8cwatQoHD58WKzWREQk\nROiAb+PGjTFz5swq74eFhSEsLEyenjNnjkgxRESkMF7hS0SkQXyGLxHVuorP/wX4DGA1MPkTkUfZ\n9HK41TS/ONzD5E9EmvFsTDOraS1/cXDMn4hIg5j8iYg0iMM+REQuGDt2rNW0pw8Zcc+fiEiDmPyJ\niDSIyZ+ISIOY/ImINIjJn4hIg5j8iYg0iMmfiEiDmPyJiDSIyZ+ISIN4hS8RUS3Iajdffl0Xrg7m\nnj8RkQYJ7fkXFBQgKSkJ165dQ/PmzTFhwgT4+vpaLXP+/HkkJyfj9u3b8PLywnPPPYeoqCihShMR\nkRih5L9x40Z07NgRgwYNwsaNG7Fx40YMHTrUapn69etjzJgxaNGiBXJzc/HOO+/gsccew3333SdU\ncSIicp/QsE9GRgb69OkDAOjTpw8yMjKqLBMSEoIWLVoAAPz9/dG0aVPcuHFDpFgiIhIklPyvX78O\nPz8/AICfn5/TpG42m1FaWoqgoCCRYomISJDTYZ+5c+ciPz+/yvuDBw+uVkF5eXlYunQpYmNj4eVl\n+zvHaDTCaDQCABITExEQEGB3fXq93uF8R9SKVbNsttkzYtUsm232jNjK3K6DswVmzJhhd17Tpk2R\nl5cHPz8/5OXloUmTJjaXKywsRGJiIgYPHowOHTrYXV90dDSio6PlaUenQomcKqVWrJpls82eEatm\n2WyzZ8RWVnk9ISEhLsUJDftERkZi165dAIBdu3ahS5cuVZYpLS3F4sWL0bt3b/To0UOkOCIiUojQ\n2T6DBg1CUlISduzYgYCAAEycOBEAcObMGWzfvh2jRo2CyWTCyZMncfPmTezcuRMAEBsbi9atW4vW\nnYiI3CSU/Bs3boyZM2dWeT8sLAxhYWEAgN69e6N3794ixRARkcJ4hS8RkQYx+RMRaRCTPxGRBvGu\nnkREdVzMw2usppU4VZR7/kREGsTkT0SkQUz+REQaxORPRKRBTP5ERBrE5E9EpEFM/kREGsTkT0Sk\nQUz+REQapJMkSVK7EkREVLs8ds//nXfe8bhYNctmmz0jVs2y2WbPiFUiHvDg5E9ERO5j8ici0iDv\n+Pj4eLUr4a62bdt6XKyaZbPNnhGrZtlss2fEKhHPA75ERBrEYR8iIg1i8ici0iAmfyIiDfKo5F9Y\nWAiTyYTNmzdj8+bNMJlMuHXrlkux+fn5yM/PBwDcuHED6enpuHDhQrXrkJWVhfT0dFy6dMnpstnZ\n2SguLgYASJKEX3/9FStXrsS2bdtQVlZmN67iuktKSqzmnT59utp1VtuXX37p8rKFhYW4cuVKlff/\n+OMPJaukOLPZDLPZDAC4ePEiNm/ejIMHD7q1roKCArfirly5gn379uHixYtuxXuq/fv3q10F7Nu3\nr9ox7m7nioqKityO9ZizfXbt2oUPP/wQXl5eqF+/PsrKyvDHH3/gyy+/xH333YfWrVvbjd2+fTs+\n+ugj7NixA/Xq1cPatWtx69Yt/PDDD2jQoAHatGljN3bhwoXo2bMnACAjIwMffPABSktL8f3336Nh\nw4YOy50xYwb69+8PvV6PdevWwWw2o2PHjjh16hQOHDiALl262IxLSEjAU089BQCYOnWq/Lq8PhWn\n3fHrr786bLMjn376KSIjI+3OX7lyJQ4dOmT1t2PHDuTm5uLQoUPo3Lmz3ViTyYQFCxbg4MGD2Lp1\nK8LCwuDv7w8AmD9/vsN2WywWGI1GZGRkQK/XIyAgQJ73zTff4KGHHnLYrjt37mDLli04ffo02rRp\ng99++w2pqak4f/48OnToAL3e/uOuv/76a2zduhUHDhxAVlYWjEYj/P39sXv3buTl5eHBBx+0G1ux\nbhcvXsSMGTOwbds2/Pjjj+jQoQMMBoPd2NmzZyMiIgINGjTA7t278dlnn6GsrAxbtmyBxWJB+/bt\nHbYZuLuj8ccff6Bp06ZWbTx8+DCCg4NtxqxcuRLh4eGoV69elXV98MEH6NOnj8My//zzTyxcuBAb\nNmzApUuXEB4ejvr16wMA3n33XURHR9uNLd/xKv+7ePEikpOTERQUhEuXLqFVq1ZO21zRuHHj8Ne/\n/rVaMbYkJCTgb3/7m935p06dQkJCArZt24a2bdvio48+wqZNm/DDDz843c6OvPXWWw7LdcRjHuD+\n7bffIjExEffdd5/V+wUFBZg2bZrDDrd161YsWbIExcXFGD16NJYuXYpmzZqhoKAAs2fPRr9+/ezG\nVnxI8qZNmzBr1iwEBgbixo0bmDt3Lp588km7sRaLBQ0aNAAAHDt2DPPnz4eXlxd69+6NyZMn242r\neAJW5ZOxlDg566uvvkLfvn3tzre3RyJJEg4dOuRw3f/+97/x0EMP4bHHHpPrmpaW5tJpad999x0S\nExPh5+cHs9mMZcuWYciQIejWrZvTdn/22We4c+cO2rVrh1WrVuGhhx7CsGHD5Dr985//dBi/fPly\nBAQEoLi4GImJiWjZsiWeffZZHDhwAMnJyXjrrbfsxu7btw+LFi1CSUkJ3njjDXz88cdo1KgRBg4c\niKlTp+K5556zG1uxbmvWrMFrr72Gzp07w2w24/PPP8e8efPsxt64cQNNmjQBAPz000+YN28eGjdu\njDt37mDatGlOk9qPP/6In3/+GS1btsQnn3yC1157Td4hWb9+PTp16mQzrlmzZoiLi0NMTAx69eqF\nO3fu4Ouvv0ZGRgZefvllh2UCQHJyMl544QW0b98ev/zyC2bOnIm4uDgEBwc7/EUMAElJSejUqZPc\nbuDuF/eBAwcAAN26dbMb++qrr0Kn0wH47//RnTt35PdXr17ttO7uWr16NSZMmICioiIkJiZi8uTJ\nCA8Px9mzZ7Fq1SrMnTvXbuzmzZttvi9JktCev8ckfwDyhqvIy8vLaWLQ6/Vo0KABGjRogODgYDRr\n1gwA4Ovra3Od9sosKytDYGAgAKBJkyZOYwMCAnD8+HE88sgjaN68OXJyctC8eXPcvHnT5TIrl+Gs\nzHJvv/22zfclScL169cdxo4cORLNmze3+lx1Op1LsUlJSUhNTcXhw4fxyiuvwN/fHxs2bHD4JVnO\nYrHAz88PANCuXTvMmjULiYmJyMnJcdpus9mMxYsXAwCefvpprFixAosXL8a4ceNc+sLMzMzExIkT\nIUkS3njjDcyYMQM6nQ4PPvigwy9qAPD29oaXlxcaNGiAoKAgNGrUCABQv359l7cXAOTl5cm/jNq1\naycPGToqNzc3F/7+/vDx8ZF3NOrVqweLxeK0vF9++QULFiyAj48PsrKysGTJEly7dg3PPPOMw8/s\nueeeQ69evZCSkoLt27cjNzcXPXr0wMKFC+U6OFJUVCR/sQwcOBBt27bFe++9hzFjxjj9vObNm4cv\nv/wS7dq1w1NPPQWdTof//Oc/GD16tNNyn3zySRQWFmLo0KFyDoiNjcXy5cudxooqKyvD/fffD+Bu\n7ggPDwdw91x9Z9t5/fr1ePbZZ+Ht7V1lnsjOoMck/3/84x+YMmUKHn30UfknUnZ2No4dO+Z0r06n\n06G0tBR6vd7qnhjFxcVOP7zz589j2LBhkCQJJSUlyM/PR7NmzVBaWur0H+zNN9/E8uXL8fXXX6Nh\nw4aIi4tD69atcevWLbz66qt243JycrBy5coqrwEgNzfXYZnlrl+/jmnTplX5pSRJEmbMmOEwNigo\nCDNnzrQaOin3r3/9y2Fsw4YN8dprr+Hs2bNYunQpOnfu7HIHbdiwIa5cuSIPN/j5+SE+Ph6LFi1y\nenymtLRUfu3t7Y0333wTGzZswJw5c6q1d6TT6dC5c2c5Cel0OqcJSa/X486dO2jQoAESExPl9wsL\nC+Hl5fiw2tWrV7FgwQJIkoScnBx5PQCc7gUPGzYM8+bNQ7du3dCqVSvMmTMHnTp1wsmTJ13+svXx\n8QEABAYGIj4+Hu+//z6uXbvm8jYrKyuDJElo1aqVS4m/XGFhofwl+cgjj2DSpEl4//33nY6Dt2vX\nDtOnT8fWrVsxZ84cvPzyyy5/wY4YMQJnz57FBx98gC5duuDpp5+u1pfzpEmTbC7vyk5Rxc9zyJAh\nVvMq9l1b2rRpg65du9r89bxjxw6HsY541EVeBQUFOHLkCHJzcyFJEgwGAx577DH4+vo6jMvOzoaf\nn1+Vb87c3FxcvHgRjz76aLXrcuvWLVy6dAkdOnRwuuzFixeRmZmJsrIyGAwGhIWFOUwKO3fudLg+\nV/6xP/74Y/Tt21few6jogw8+wLhx4+zGbt26FeHh4TaPZ/z0008uj5FKkoSff/4Zp0+fxtixY50u\nf/78efj4+FQZay4tLcXevXvxxBNP2I398MMP0bt37ypDFb/88gtWrFiB9evXOyy7fNijPBmWu3Ll\nCpYvX+7wZ3lJSUmV8W/g7rBMfn6+vMdXUFBQpa+eOHHCarpt27bw8fFBfn4+9u3bh6efftphvQsL\nC7Fnzx5cvnwZFosF/v7+6NKlC1q2bOkwDrh7zGDYsGFW27msrAwff/yxfMzDlm+++QY7d+7EkCFD\nEBUVhdzcXKxatQo3btzA66+/7nTcfc+ePQgMDKzyv5OdnY0NGzZg1KhRTusO3P3//fzzz3H27Fks\nW7bMpRjg7pfe1q1bsW/fPly9ehWffvqpS3HXrl1zOL958+Z25+3fvx8dO3as8gV55coVpKen4+9/\n/7vd2MuXL8PX19dqqKtc+c6oW6R7zNSpUzUVK+rmzZtuxx45csTtWLU+L3fqbLFYhOLLxcXFVXlv\n3bp1bq9PJFaSJCk7O1vKy8uzOe/kyZPy68p9ZOXKlVJhYWGVmIMHD0rjx493Wq6aba4oNzdXOnDg\nQJX3q7uNT548KSUnJztcpq60uSKPOtXTFZVPjfTE2FOnTmHXrl3y9Pvvv4/Zs2dj9uzZOH78uNvl\n2OJoj9aZdevWuR2r1mftTp0r/tQXabNk40f2kSNH3F6fSCwAGAwGu3uNFX8xVu4jw4cPR8OGDavE\ndO7cGQsXLnRarpptrsjPzw8RERFV3ndlG58/fx5r165FbGwsUlNTnf7SqittrshjxvxdVZ0xvLoa\n+9VXX2HEiBHy9OXLlxEbG4uioiJ89913eOSRR9wuqzJbCak2YtX6rEXqLBpvq94Wi8XhOLejIU2R\n2Oqo3OYlS5Zg4sSJAIC1a9di6NCh8rwFCxZg+vTpDtdX19tsbxtfvnwZJpMJaWlp8PX1RVRUFCRJ\nwqxZs5yusy62+Z5L/veC27fG3IrvAAAY4ElEQVRvW42btmjRQj7Y42zsurrUSsJqEa2z0m2+dOkS\n3nnnHZsJR6fTORzLFomtjsptrngR3rFjx6zm3bhxw+n66nqb7W3jCRMmIDw8HFOmTJGPS23ZssWl\nddbFNt9zyV+tPVklYytftVzxtM3yq5Q9nVqftZps1btVq1YuDZXYIhIrwtEXoCtfjp7YZuDu2T5p\naWmYPXs2HnvsMfTs2dPlvlgX2+wxY/4rVqxAYWGh0+XGjBnj8bEhISE2bw1w4MABhISEOF1fdYgk\nUltnN6j1WbvK0RkZ7sZXPA6TlZVlNS89PV1+PXPmTKGy1VK5j9y5cwfnzp3D2bNnUVxcjLNnz8p/\nzs5Z9wT2+kjXrl0xYcIEJCUl4eGHH8aWLVtw/fp1JCcn19i4fE3ymNs7XLhwAcnJyWjcuLF86pwt\nTZs29fjYdu3aYdmyZTh37hyys7NhNpuxbds27NixA7GxsWjcuLHddZU7fvy4fEFaVlaW1fn+6enp\n8rBSjx495Evry504cQLXrl2z+1f+zxEVFaVYm0VjReosGv/+++/Lt56YM2eO1W0oli5dKk9X/pyB\nuxdkObpFiCMisYD7fSQ9PR1HjhzB0aNH4ePjg6NHj8p/Pj4+Tk9FVqvNon2knF6vxwMPPIBevXph\nwIABKCgowPbt2x22W83tbI9Hneefm5uL1atX4+bNmxgwYIDVT0xHl3V7YmxJSQl+++03+SZdoaGh\naNGiBfbs2YP/+Z//cVgmAEyZMgULFiyo8trWdGUVL1Qqp9Pp8McffyAnJ8fu+d/l1Pi8ROssEh8X\nFyf/LK/42tZ0ZY62A3B3W9VEbPl8d/qI2WyGwWCQr8beuXMn0tPT0bx5c7z44otOD0Cq1WbRPlLZ\nnTt3cPHiRTRv3tzmOfgVqbmd7fGoMX9/f39ERETgf//3f7F//36rC6WcJRVPi61Xrx769euHc+fO\nIS0tDRs2bEBgYKDT8spV/E6v/P3u7Pu+4lXQwN1TT7/99lv4+flZnYVkjxqfl2idReJFbsdx+vRp\nBAQEoGfPnmjXrp3TeioVC7jfR5KTk+WrxE+cOIH169dj+PDhOH/+PD799FNMmjSpxuotEivaR/bv\n349Vq1bB19cXMTExSElJQbNmzZCVlYWXX37Z4Z6/mtvZHo9J/hcuXMCKFSvg5+eH9957T97ruBdj\nRU4pK6fE/YGOHTuGb775BjqdDv/4xz9cuhJarc9apM6i8RVv0VD+GribQCsfA6gsOTkZR48exZ49\ne7Bnzx5ERESgZ8+eCA0NdVquSCzgfh+xWCzy3r3JZEL//v3RvXt3dO/e3el9kETrLdpmwP0+kpqa\nimnTpqGwsBCzZ8/G4sWLERQUhOvXr2POnDkOk7/abbbFY5L/kiVL8Nprr+Gxxx6752NFTikrJ5KQ\nDh48iG+//RaNGjXC4MGDbd4iwh61PmuROovGx8XFya8HDhxYrXK9vLzQqVMndOrUCSUlJUhLS0N8\nfDyef/55p7fREIkF3O8jFosFZWVl8Pb2xvHjx/HGG29YzaurbRbtIzqdTj7hIjAwEEFBQQDuHoOy\nddM1peotup3ttsdTxvzt3T/l1KlTTsfBPS323//+N9LS0nD69Gn5lLJPPvmkWncfrHzPmMoc3d8+\nJiYG/v7+eOCBB2zuAToaY1TrsxapsxLxIkpKSnDw4EGkpaXh2rVrePzxx9GvXz/5WQY1FetuH/n2\n229x6NAhNG7cGNnZ2ViwYAF0Op1L90FSot7uxopu48mTJ2PWrFmQJAlz5syx+iU+e/ZsLFq0qEbq\nLRprj8ck/4rOnz+PPXv2YO/evQgMDETXrl1d/gb0pNiioiJkZGQgLS0Nx48fR58+fdC1a1e39oyr\nQ+SLo6La/LxE6ywSn5GRgZycHPkmbFOnTpUvdho6dCi6d+9uN3bZsmW4cOECOnfujKioKIdnOSkZ\nK+r06dPIz8/Ho48+Kt8M7/LlyygqKnL67Aa12izaR2JjY+Vbm1fm7GKruridPSb52xoH/+GHH/DR\nRx/dk7GVFRQUYO/evTCZTC6N/YskpHLFxcW4cuUKdDodgoKCbJ6qWJnan5c7dRaNnzFjBsaNGyff\nAnvy5MmYOXMm7ty5g48++sjh+f0xMTHynR4r7o1KkuT0ASMisYAyfcQdarYZEO8jzly4cKHKeLza\nbbbFY8b8RcbBPTG2Ml9fXzz11FMuP8Lx+++/t7ptc0lJCebPny8nJEf/2GVlZVi/fj1+/fVXBAQE\nyPea79u3LwYPHuzwkYZqfV4idRaNLy0ttXr2QXh4OBo3biw/VcuR6p5eqFQsINZHRKjVZtE+4qpl\ny5ZVOT1Tze1sj8ckf5FLqz0xVpRIQlqzZg2KioqwbNky+e6NhYWFWLNmDdasWYPhw4fbjVXr8xKp\ns2h85ZtujRw5Un7tyr1uKisf7tuzZw/efffdGosV6SNKq402i/YRV7naZ2trO9vjMVf4tmzZEj16\n9EB0dDRKSkrwyy+/4MKFC8jJyYFer7f7sGlPjRW1adMmPPPMM/J0xVvXbty40WpeZStXrsT06dOt\nDr7Wq1cPERER+Pzzzx2Ovav1eYnUWTTebDbj5s2bVca6t2/fjtLSUpf2oEtLS7F//36kpqZixYoV\nqFevHnr37u3S7TzcjRXpI0qo7TaL9hFXGY1Gu7/Q1djO9njMnn85Hx8fPPHEE3jiiSfkcfCNGze6\ndBDUE2Pd1b59exiNRkRHR1u9v337doSFhTmMtffoQi8vL5evEajtz0u0ziLxw4YNw6JFi5CWloY2\nbdoAAM6ePYuSkhKn572Xn7995MgRPPzww+jduzfOnDnj0jNpRWIBsT4iQq02K9Gv3aXmdrbHY5J/\ncXExtm/fjitXruD+++9Hv379XB4H98RYUSIJqWXLlti1axf69Olj9f7u3bud7mWo9XmJ1Fk0vmnT\nppg3bx6OHz8uP2s4IiLCpecuJCQkIDw8HHPnzpXvs/P55587jRONBcT6iAi12izaR7Kzs20+17oy\nW8cO1NzO9njM2T5JSUnw9vbGgw8+iEOHDqF58+Yuj9F5YqxSKiak0NBQlxJSbm4uFi9ejPr168tD\nGWfOnEFxcTEmT57s8NxitT4vkTorEV+Zq2Oy5bfvSE9PR2BgIHr27IkNGza4dIaTSGxF7vQREWq1\nWXQbO7snVk3VW6ntXJnHJP9Jkybh/fffB3D3qP3UqVNd3hCeGFsTqnuQqDwpSJKE0NBQdOzY0WmM\n2p+XO3VWKr60tBQHDx6Uf6J369YNXbt2RWRkpEvxp06dkv/JW7duja5du1YZkqmJ2IqUOJBYHWq0\n2d1t7Owmfa6qC9sZ8KBhn4o/pZxdSn0vxCrFVkJyNoRSfvZK69atrW4lW/6+o7s2qvV5idRZNF6p\nMdnw8HCEh4dj+PDhOHr0KEwmk/yPbevccaVi3ekjSqnNNov2kdzcXKxcudLufFduDudOvZWKrcxj\n9vxjYmLkKwklSUJxcTEaNGjg8kUSnhYrqnJCioqKwqpVq1y6RUTFKxltXVTi6EpGtT4vkTor0ebw\n8HDExsbKY7JjxoxR7DGKgNiQg71YkT5SG5Rus2gfGT16NF588UW78509x8AVNbGd7fGYPX+1LpKo\nixdnuELkIFF8fLzbT7xS6/MSqbNofGJiItLS0uTPumfPni7d4Kw6auKxlzV1IFEpSrdZtI80btxY\nkQTvSG0+3tRjHuNI1ZOYmIj27dtj7ty5mDt3Lnbs2OFyQlq8eHEN1055onUWiW/Tpg2GDh2KpUuX\n4oUXXsC5c+dQWlqK9957D0ajUahe5URORbQXK9JHaoPSbRbtI0pdAexITWxnezxmz5+qp02bNnJS\nKj9IVJ6QnB0k8pCRQCuidVaqzY7GZOsakT7iiUS38ciRI3H27Fm7853d0K6uYfLXgOomJKUObNUm\n0TqLxNtLCE2aNJFvmmaPxWKxelqZPbb2OkViK6vNLy212izaR9asWeNwvqMbLtaV7VyRxxzwpepx\ntIcCON5LqY0DW0oTrbNI/OzZsx2u21FSmDx5Ml5//XV06NDB4TqUjgXE+ogItdqsZr9Wczvbwz3/\ne5TIXkptHNhSmmidReKr83jNyt544w2sXLkSDzzwAIYOHer0dEOlYgGxPiJCrTaL9pH09HSH8x09\nY1rN7WwP9/ypimnTpiEhIUHtalSLaJ1ros1Hjx7Fpk2b5Ied2yNJErZv344ffvgBnTp1sjpw52wo\nQiRWTWq0WXQbx8TEoHXr1njggQdsznd2XUdd287c89cYVxKSrX+QK1euIC0tDSaTSb4Kty4RrbNI\n/PHjx5GcnIzc3Fx06dIFzz33HJYtWwZJkvDcc885rXtBQQHMZjOaNGmCtm3bVuusDZFYe1z90hKh\nRptF+8ikSZNgMpnw559/IjIyEr169arWnXnr2nbmnv89yllCcvQTtVxeXh5MJhP27NmDP//8E4MG\nDUK3bt1q9XGB1SVaZ3fi4+LiMGzYMHTo0AGHDh3C8uXLERMT49Itkbdt24YffvgBzz77LJ566qlq\n/VOLxALK9BF3qNlmQLyPFBUVYf/+/TCZTLh58yaGDBni9BGQarfZFu7536O++OILvPHGG3JCmjZt\nmssJyWg0Ii0tDbm5uejRowdGjRqFhQsX4oUXXqiFmrtHtM4i8TqdDg8//DAAoGvXrlizZo3L98I/\ndeoU5s2bh6ZNm7q0vFKxgFgfEaFWm5Xq1/Xr10ejRo3QsGFDZGdno7i4uEbrLbqd7WHyv0eJJKSU\nlBR06NABY8eOle/rXtP3OxclWmeR+Fu3blkdDJQkyWra0R702LFjq7zn6lCESCwg1kdEqNVm0T5y\n/PhxpKWlwWw2o2PHjnjmmWdcfu6BmtvZHib/e5RIQvr000+xb98+fPHFF8jPz0ePHj1QVlZWo/UV\nJVpnkfiHHnoIBw4csDvt7hBbxefr1kSsSB9RQm23WbSPzJ07F/fffz/Cw8NRWlqKXbt2YdeuXfJ8\nVw68qrGd7eGY/z3K2b2+Xb3jZE5ODtLS0pCWlobi4mJ06dIFL730khJVrDGida7NNlceiujRowcW\nLlzo0s3VRGIB5fpIdanZ5nLubOOdO3c6nO/oNNK60OYqJCIXXbp0Sfrqq6/Urka1iNbZ1fiysjLp\n+vXr8nRJSYm0fft2afz48Q7jBg8eLM2cOVMym83ye7GxsS7VTSRWTXWtzbXRr+tamyVJkjjscw+z\nWCwoKChAkyZNANy9b/vOnTuxZcsWJCUl2Y3bvXs3AKB3795W7584cQItWrSouQoLEK2zSHxaWho+\n++wz+Pj4IDg4GC+88AKWLVuGsLAwvPXWWw5jRYYilBiec7ePiFCrzaJ9JDEx0eExgilTptRIvWtq\nGJbDPvcoRwnpn//8p8NL9+Pi4jB79mw0bNjQ6v3bt28jPj5e1aeR2SNaZ5H4SZMmYfLkyQgODsbZ\ns2cxffp0jB8/Hl27dq1WG7Kzs2EymdwabnInVqSPKKU22yzaR06cOOFwvrPTPd2tt1KxVQj/dqA6\naeLEiVJmZqYkSZJ05swZaciQIVJ6erpLsZMmTXJrnppE6ywSHxcXZzU9btw4p+U5IzIU4WqsSB+p\nCTXd5prs10uWLHErrja2sz0c9rlH6fV6+erDtm3bIjAw0OU90bKyMhQVFclP1Sp3+/ZtlJaWKl5X\nJYjWWST++vXr2Lx5szxdVFRkNf23v/3NbmxmZibWrFmDq1evIjQ0FK+++ir8/f0REhLi9PxzkVhA\nrI+IUKvNNdmvT58+XWP1Ft3O9njHx8fHux1NddY333wD4G6nPH36tPyTtXza0R0Ci4uLsWnTJvzl\nL3/BfffdBwDIysrCxx9/jG7duuEvf/lLzTegmkTrLBJfnjzK/9q2bSu/LisrczgcsGjRInTv3h1/\n//vfcfv2bRiNRkRFRbnUZpFYQKyPiFCrzTXZr7ds2eLwS17N7WwP9/zvUf3798ft27dtTju7sGXg\nwIHw8fFBfHw8ioqKAAA+Pj4YNGgQBgwYUHOVFiBaZ5F4R3tfZrPZYezt27fl++YPHDjQ4UFDJWMB\nsT4iQq02i/YRR7fAdnYAVs3tbA+T/z1KJCEBwIABAzBgwAAUFRVBkqQqB8nqItE6K9XmixcvyueQ\nN2rUCImJiXaXLSkpwblz5+SnTBUXF1tNOzroKhILiPcRd6nZZpFt7OgW2C1btnQYq2ab7eHZPhpR\nnYRUcby6XJMmTRAeHi4/6LuuEa2zaPy1a9fkz9fLywvZ2dmYP3++01iRB8GIxNpSnT4iQq0211a/\nPnr0KB599FGr9+rSdi7H5H8Pczchff3111XeKygowJEjR/DCCy+gZ8+eNVVlt4nWWSR++vTpKCws\nRFRUFHr27IkWLVogNjZW/ArMCmwlFCVi3e0jtUHpNtdWv54yZYrbp0PX1Ha2hcM+96iKCWnixIly\nQnLln9recEBBQQHmzp1bJ5O/aJ1F4ps0aYKcnBxcv34dN27cQIsWLRQfM1+3bp3bScFerEgfqQ1K\nt7m2+rXI/nRNbGd7mPzvUTWRkHx9fYU6thpE6+xKfFxcHAoLC7Fv3z589dVXuHLlCgoLC2E2m9Gu\nXTu3y65IpA32YmvjS0tETbTZFqX7tchnWFttBpj871k1kZCOHz8unyLnKUTr7Gp8o0aN0K9fP/Tr\n1w/5+fkwmUz4/PPPkZOTg48//tjt8suJJBR7sbXxpSWiJtpsS13q17XVZoDJ/57mbkKaNGlSlY5U\nUFAAPz8/jBkzpqar7RbROivZ5mbNmuGZZ57BM888g2vXrlUrtrbV9JdWXVJb/bp58+aKrasmMflr\nRHUS0jvvvGM1rdPp4OvrW+XKyLpEtM4i8c4O7ilxXrZIQnE1tq59aSndZqX6dcVnHpRr1KgR7r//\nfjRt2hRvv/129SpbQW1s53I82+cepURC+vPPP3Hp0iUAd89jrsvP7i0nWmd34keOHImAgAD07NnT\n5nCJKzf8cpZQaiK2Nr60HFGjzYB4H5k/fz5Onz4tPwXtxIkTaN++PTIzM/H8889XuWuoUvUWibWF\ne/73qNOnTztMSI4UFhZi4cKFyMnJwf333w9JknDhwgUEBARg8uTJaNSoUQ3V2n2idRaJT05OxtGj\nR7Fnzx7s2bMHERER6NmzJ0JDQ12u/44dO9xOKO7GivQRJdR2m5Xq1zqdDklJSWjWrBkAID8/HytW\nrMB7772HWbNm1ci2Eo21ye1bwlGdVlZWJh06dEhaunSpNHnyZGn9+vXSn3/+6VJsSkqKtHr1aqms\nrMxqfWvWrJFSUlJqqspCROusVJuLi4ulX3/9VRoxYoT0448/uhw3f/58KS8vT57Oy8uTFi1aJN28\neVOaOHFijcSK9BEl1HabldrGlddvsVjk9yZPnqx4vZWItcWrel8V5Cm8vLzQqVMnjBkzBgkJCQgO\nDkZ8fDx++uknp7HHjh3Dyy+/DC+v/3YPLy8vDBkyBMeOHavJartNtM6i8SUlJUhPT8fSpUvx888/\n469//Wu1noF77do1eU8SAJo2bYrMzEz4+vrC29u7RmJF+ogSarvNSvXrBx98EImJidi5cyd27tyJ\nBQsW4MEHH0RRUZHTs4bU2M72cNjnHlZSUoKDBw8iLS0N165dczkh6fV6m53J29sben3d7DKidRaJ\nX7ZsGS5cuIDOnTvj+eefd+vYSHlC6d69OwBg3759LicUkVh3+4gSarvNSvXrkSNHIj09HadOnQJw\n99m93bp1g06nc3qrBbW2sy118z+ZhIkkpMo3kqqort7PX7TOIvG//fYbGjRogMzMTKu9ZkmSoNPp\nsHr1aqfliyQUd2OV+NISUdttVqpf63Q6hIeHQ6/XQ6fToV27di6fY6/GdraHyf8eJZKQmjVrhi++\n+MLuvLpItM4i8ampqc4r6IRIQnE3VokvLRG13Wal+rXJZMLatWvls7hWrlyJV155Rd4jV7reSsTa\nXJ9k62uQiGpV5YRy8uRJlxOKSKyaPLXNkydPxvTp0+XTK2/cuIG5c+di0aJFTmPrVJurfYiY7nkb\nN26UX5tMJqt569atq+3quES0zmq3+e2335by8/Pl6evXr0tvv/12jceqqbbbrNQ2rnxmTVlZmctn\n29Sl7cyzfagKk8kkv964caPVvCNHjtR2dVwiWme122yxWKwu1PH19YXFYqnxWDXVdpuV2sadOnVC\nQkKCfLZPYmIiOnfuXGP1ViLWFo75UxVShZFAqdKoYOXpukK0zmq3uTyhlN9W2GQyuZxQRGLVVNtt\nVmobv/LKK9i3bx/+7//+D5IkITo62uUH39el7czkT1VUPIhU+YBSXbrlb0WidVa7zSIJRSRWTbXd\nZiW3cffu3d0aa69L25kHfKmKmJgY+Pj4QJIkFBcXo0GDBgDu7h2VlJRg/fr1KtewKtE6e2KbqXpE\nt/Grr75q80tCqqWzo5TG5E+kIpGE4qnJiG3+LzXbzORPRKRBPNuHiEiDmPyJiDSIyZ+ISIOY/ImI\nNIjJn4hIg/4fpiHEUGH7KncAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=dfsub.columns)\n",
    "weights2 = weights.sort_values(ascending = False)\n",
    "weights2.plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "#df_c = df_c.sort_values('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression:  Interpretation of Weights\n",
    "\n",
    "- The most important feature in predicting delinquency is how delinquent the most recent payment was.  The more delinquent the payment, the more likely the account is to default.  The second most important feature is the log of the most recent payment amount.  The higher the payment, the less likely the account is to default.  All of this is consistent with intuitive expectations.\n",
    "\n",
    "- In general, the most important features are the delinquency status of some payments made, the amounts paid and the credit limit.  We are ignoring the Education Level 4, because that is a catch-all category with few values.\n",
    "\n",
    "We are struck by the preponderance of low weights in this data set.  This could be due to:\n",
    "- The existence of serial correlation among variables, which include sequential payments and the tendency of customers to be consistent in terms of the delinquency of the payments they make from month to month.  \n",
    "\n",
    "- We may need to include additional (calculated) variables, such as the number of times delinquent.\n",
    "- We may need to segment customers into groups, for example light and heavy users of their cards.\n",
    "- The relationship between certain explanatory variables and the response may not be modeled correctly.  For example, the \"Pay\" (Delinquency) variables are ordinal, and we are treating them as continuous.  We may need to treat them as categorical.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX:  Description of the Data Set\n",
    "\n",
    "#### Attribute Information\n",
    "The data used is \"Default of Credit Card Clients\" from UCI. It was attained by I-Cheng Yeh with Chung Hua University and Tamkang University in Taiwan. The original goal was to predict default rates.\n",
    "\n",
    "The data has a 6 month history of 30,000 Taiwanese credit account balances and transactions. Each observation contains a binary reponse variable \"default\" with values 1 indicating a default occured and 0 indicating no default occured.\n",
    "\n",
    "The following explanatory variables are included:\n",
    "\n",
    " - LIMIT_BAL = Total credit amount allowed\n",
    " \n",
    " - SEX\n",
    "     -  1 = Male\n",
    "     -  2 = Female\n",
    " \n",
    " - EDUCATION\n",
    "     - 1 = Graduate School\n",
    "     - 2 = University\n",
    "     - 3 = High School\n",
    "     - 4 = Other\n",
    "   \n",
    " - MARRIAGE\n",
    "     - 1 = Married\n",
    "     - 2 = Single\n",
    "     - 3 = Other\n",
    "       \n",
    " - AGE = Credit holder age in years\n",
    " \n",
    "Payment history (2005)\n",
    " - PAY_0 = September\n",
    " - PAY_2 = August\n",
    " - PAY_3 = July\n",
    " - PAY_4 = June\n",
    " - PAY_5 = May\n",
    " - PAY_6 = April\n",
    "      -  -1 = payment received on time\n",
    "      -   1 = payment received one month late\n",
    "      -   2 = payment received two months late\n",
    "      -   \"......\"\n",
    "      -   9 = payment received nine months late or more\n",
    "         \n",
    "Statement amount (NT dollars, 2005)\n",
    " - BILL_AMT1 = September\n",
    " - BILL_AMT2 = August\n",
    " - BILL_AMT3 = July\n",
    " - BILL_AMT4 = June\n",
    " - BILL_AMT5 = May\n",
    " - BILL_AMT6 = April\n",
    " \n",
    "Payment amount (NT dollars, 2005).\n",
    " - PAY_AMT1 = September\n",
    " - PAY_AMT2 = August\n",
    " - PAY_AMT3 = July\n",
    " - PAY_AMT4 = June\n",
    " - PAY_AMT5 = May\n",
    " - PAY_AMT6 = April\n",
    "\n",
    "Original Source Data Set Information  \n",
    "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create logistic regression object\n",
    "lr_clf = LogisticRegression(penalty='l2', C=12, class_weight=None)\n",
    "\n",
    "#Set our iteration count variablew to 0\n",
    "iter_num=0\n",
    "\n",
    "#Set our train and test data set variables:\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "#Fit the model, output accuracy and confusion matrices:\n",
    "    lr_clf.fit(X_train,y_train)\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29532</td>\n",
       "      <td>-0.013172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>468</td>\n",
       "      <td>-0.239316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               len      mean median\n",
       "             PAY_0     PAY_0  PAY_0\n",
       "EDUCATION_4                        \n",
       "0            29532 -0.013172      0\n",
       "1              468 -0.239316      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(dfsub,index = ['EDUCATION_4'],values = [\"PAY_0\"], aggfunc=[len, np.mean, np.median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
